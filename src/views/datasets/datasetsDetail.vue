<template>
  <div v-if="!datasetName">
    <el-empty description="æœªæŒ‡å®šæ•°æ®é›†ï¼Œè¯·å‰å¾€<æ•°æ®é›†-ç›®å½•>é¡µæŸ¥é˜… â•°(*Â°â–½Â°*)â•¯">
      <el-button type="primary" @click="redirectToDatasetCatalog">å‰å¾€æ•°æ®é›†-ç›®å½•</el-button>
    </el-empty>
  </div>

  <div v-else v-loading="queryLoading">
    <!-- æ•°æ®å…ƒæ•°æ® -->
    <div class="detail-header-container">
      <el-row>
        <el-col><div class="dataset-meta-name">ã€Mock å¼€å‘ä¸­ã€‘{{ datasetMeta.name }}</div></el-col>
        <el-col v-if="datasetMeta.source">
          <div class="dataset-meta-source"><span>æ¥æº: </span>{{ datasetMeta.source }}</div>
        </el-col>
        <el-col>
          <el-tag
            v-for="val in [datasetMeta.is_open_source]"
            class="dataset-meta-tag"
            :key="val"
            type="info"
            @click.prevent.stop
          >
            <span>æ•°æ®åè®®ï¼š</span>{{ isOSSFormat(val) }}
          </el-tag>
          <el-tag
            class="dataset-meta-tag"
            :key="datasetMeta.registrant"
            type="info"
            @click.prevent.stop
          >
            <el-icon style="display: inline-block; margin-right: 4px;"><User /></el-icon> {{ datasetMeta.registrant }} æä¾›
          </el-tag>
          <el-tag
            class="dataset-meta-tag"
            :key="datasetMeta.updated_at"
            type="info"
            @click.prevent.stop
          >
            <span>æ›´æ–°äºï¼š</span>{{ formatDate('yyyy-MM-dd hh:mm:ss', datasetMeta.updated_at) }}
          </el-tag>
          <el-divider direction="vertical" />
          <el-popover
            placement="right"
            title="å­˜å‚¨ä¿¡æ¯æ¦‚è§ˆ"
            :width="500"
            trigger="hover"
          >
            <template #reference>
              <el-button size="small" @click.prevent.stop class="m-2" type="success" plain><el-icon ><View /></el-icon>æŸ¥çœ‹å­˜å‚¨</el-button>
            </template>
            <template #default>
              <el-row justify="space-between" v-for="(datasetPath, idx) in [datasetMeta.src_paths, datasetMeta.media_root_dir, datasetMeta.converted_paths, datasetMeta.converted_preview_paths]">
                <el-col :span="4">
                  <el-button text :disabled="isContentEmpty(datasetPath)" @click.prevent="handleClipboard(datasetPath)">
                    <el-icon ><CopyDocument /></el-icon><span>{{ datasetPathLabelMap[idx] }}</span>
                  </el-button>
                </el-col>
                <el-col :span="18">
                  <p class="dataset-name-multiline" style="margin: 0 0 15px 0;">{{ datasetPath || 'æ— ' }}</p>
                </el-col>
              </el-row>
            </template>
          </el-popover>
        </el-col>
        <el-col>
          <el-tag
            v-for="stage in datasetMeta.stages"
            class="dataset-meta-click-tag"
            :key="stage"
            type="primary"
            @click.prevent.stop="redirectToDatasetCatalog('stage', [stage])"
          >
            {{ stage }}
          </el-tag>
          <div v-for="(group,idx) in datasetMeta.labels" :key="group.label_name" style="display: inline">
            <el-tag
              class="dataset-meta-click-tag"
              v-for="val in group.label_values"
              :key="val"
              type="primary"
              @click.prevent.stop="redirectToDatasetCatalog('labels', [idx, val])"
            >
              {{ val }}
            </el-tag>
          </div>
        </el-col>
      </el-row>
    </div>
    <!-- æ•°æ®å¯è§†å†…å®¹ -->
    <div class="detail-content-container">
      <el-row>
        <el-col class="splits-wrapper">
          <div v-if="datasetSplitLenght > 0" class="splits-label">Splits ({{ datasetSplitLenght }}):</div>
          <el-select v-model="datasetSplit" placeholder="è¯·é€‰æ‹©åˆ†ç‰‡" style="width: 240px">
            <el-option
              v-for="(data, key) in datasetMeta.splits"
              :key="key"
              :label="key"
              :value="key"
            />
          </el-select>
        </el-col>
        <el-col>
          <DatasetViewer
            :all-table-data="allTableData"
            :query-loading="queryLoading"
          />
        </el-col>
      </el-row>
    </div>
  </div>
</template>

<script setup>
import { useRoute, useRouter } from 'vue-router'
import { ref, onMounted, reactive, computed, watch } from 'vue'
import { ElMessage } from 'element-plus'
import DatasetViewer from '@/components/DatasetViewer.vue'
import { formatDate, copyText } from '@/utils'

const route = useRoute()
const router = useRouter()

// --- çŠ¶æ€å®šä¹‰ ---
const datasetName = ref("")
const datasetSplit = ref("")
const datasetSplitLenght = ref(0)
const datasetMeta = ref({ splits: {} })
const queryLoading = ref(false)
const datasetPathLabelMap = ref(["æºå€ï¼š", "åª’ä½“ï¼š", "ç´¢å¼•ï¼š", "é¢„è§ˆï¼š"])

const allTableData = ref([])    // å½“å‰é€‰ä¸­ Split çš„å…¨é‡æ•°æ®

const fetchData = async () => {
  if (!datasetName.value) return

  try {
    queryLoading.value = true
    // æ¨¡æ‹Ÿæ¥å£è¯·æ±‚
    // const res = await api.getDatasetDetail(datasetName.value)
    const res = {
      "name": "VideoChat2-IT",
      "source": "https://huggingface.co/datasets/OpenGVLab/VideoChat2-IT",
      "is_open_source": true,
      "size": "{'train-formatted': 670029}",
      "count": null,
      "src_paths": [
          "/mnt/cfs_bj/dataset/multi_modal/video/VideoChat2-IT"
      ],
      "src_volume_paths": [
          "/Volumes/qianfan_bos_catalog/all_data/VideoChat2-IT"
      ],
      "converted_paths": [
          "bos://llm-data-process/mnt/cfs_bj/dataset/multi_modal/video/VideoChat2-IT-formatted/train-formatted.jsonl"
      ],
      "converted_preview_paths": [
          "/mnt/cfs_bj_mt/datasets/data_platform/preview/sft/VideoChat2_IT/train-formatted_preview.jsonl"
      ],
      "media_root_dir": "bos://llm-data-process/dataset/medias/video",
      "stages": [
          "SFT"
      ],
      "parent_id": null,
      "process_note": "",
      "tags": [
          "InternVL2.5 å¼€æºsftæ•°æ®ï¼›å¤šè½®å¯¹è¯"
      ],
      "labels": [
          {
              "label_name": "æ•°æ®æ¨¡æ€",
              "label_values": [
                  "ğŸ¬ è§†é¢‘"
              ]
          },
          {
              "label_name": "æ•°æ®ç»†åˆ†ç±»å‹",
              "label_values": [
                  "General VQA"
              ]
          },
          {
              "label_name": "language",
              "label_values": [
                  "EN"
              ]
          }
      ],
      "registrant": "é™ˆæ·æŒº",
      "tables": [
          "videochat2_it_v0"
      ],
      "tokens": null,
      "groups": [
          "official",
          "group_a"
      ],
      "created_at": "2025-06-05T23:16:50.685000",
      "updated_at": "2025-10-10T13:56:57.956000",
      "splits": {
        "train-formatted_preview_2": [
          {"id": "next_qa-3441910437", "video": ["Next-QA/NExTVideo/1203/3441910437.mp4"], "relative_video": ["Next-QA/NExTVideo/1203/3441910437.mp4"], "conversations": [{"from": "human", "value": "<video>\nKeep in mind the causal and temporal aspects of the actions while watching the video, then determine the most accurate choice."}, {"from": "gpt", "value": "Answer: (D) ducked."}], "absolute_videos": ["/mnt/cfs_bj/dataset/multi_modal/video/Next-QA/NExTVideo/1203/3441910437.mp4"]},
          {"id": "next_qa-3441910437", "video": ["Next-QA/NExTVideo/1203/3441910437.mp4"], "relative_video": ["Next-QA/NExTVideo/1203/3441910437.mp4"], "conversations": [{"from": "human", "value": "<video>\nKeep in mind the causal and temporal aspects of the actions while watching the video, then determine the most accurate choice."}, {"from": "gpt", "value": "Answer: (D) ducked."}], "absolute_videos": ["/mnt/cfs_bj/dataset/multi_modal/video/Next-QA/NExTVideo/1203/3441910437.mp4"]},
        ],
        "test-formatted_preview_3": [
          {"id": "next_qa-3441910437", "video": ["Next-QA/NExTVideo/1203/3441910437.mp4"], "relative_video": ["Next-QA/NExTVideo/1203/3441910437.mp4"], "conversations": [{"from": "human", "value": "<video>\nKeep in mind the causal and temporal aspects of the actions while watching the video, then determine the most accurate choice."}, {"from": "gpt", "value": "Answer: (D) ducked."}], "absolute_videos": ["/mnt/cfs_bj/dataset/multi_modal/video/Next-QA/NExTVideo/1203/3441910437.mp4"]},
        ]
      }
    }
    datasetMeta.value = res
  } catch (err) {
    console.log(err)
    ElMessage.error('è·å–æ•°æ®é›†è¯¦æƒ…å¤±è´¥')
  } finally {
    queryLoading.value = false
  }
}

const isOSSFormat = (val) => {
  return val ? 'å¼€æº' : 'éå¼€æº'
}

watch(() => datasetMeta.value.splits, (newSplits) => {
  const keys = Object.keys(newSplits || {})
  datasetSplitLenght.value = keys.length
  if (datasetSplitLenght.value > 0) {
    datasetSplit.value = keys[0]
  }
}, { deep: true })

watch(datasetSplit, (newSplit) => {
  if (newSplit && datasetMeta.value.splits[newSplit]) {
    allTableData.value = datasetMeta.value.splits[newSplit]
  }
})

const isContentEmpty = (val) => {
  if (val === null || val === undefined) return true;
  if (typeof val === 'string') return val.trim() === '';
  if (Array.isArray(val)) return val.length === 0;
  return false;
};

const redirectToDatasetCatalog = (field, vals) => {
  let queryParams = {};
  if (field === 'stage') {
    queryParams = { stage: vals[0] };
  } else if (field === 'labels') {
    if (Array.isArray(vals) && vals.length >= 2) {
      const fieldMap = ["modality", "type", "language"];
      const targetKey = fieldMap[vals[0]];
      if (targetKey) {
        queryParams = { [targetKey]: vals[1] };
      }
    }
  }
  router.push({
    path: '/datasets/catalog',
    query: queryParams
  });
};

const handleClipboard = (text) => {
  if (!text) {
    ElMessage.closeAll();
		ElMessage({
			message: 'æ— å†…å®¹!',
			type: 'warning',
			duration: 2 * 1000,
    })
    return
  }
	copyText(text, () => {
    ElMessage.closeAll();
		ElMessage({
			message: 'Copied!',
			type: 'success',
			duration: 2 * 1000,
    })
	})
}

// --- ç”Ÿå‘½å‘¨æœŸ ---
onMounted(() => {
  const name = route.query.name
  if (name) {
    datasetName.value = name
    fetchData()
  }
})
</script>

<style lang="scss" scoped>

.detail-header-container {
  height: calc(15vh);
  background-color: var(--el-fill-color-extra-light);
  padding: 20px;
  overflow: auto;

  .dataset-meta-source {
    color: #99a0ae;
    margin-bottom: 5px;
  }

  .dataset-meta-name {
    font-weight: 700;
    margin-bottom: 10px;
  }

  .dataset-meta-tag {
    color: #000;
    border: 0;
    background-color: #fff;
    margin: 0 10px 5px 0;
  }

  .dataset-meta-click-tag {
    margin: 0 10px 5px 0;
    border: 0;
    &:hover {
      cursor: pointer;
    }
  }

  .dataset-name-multiline {
    /* å¿…é¡»ä½¿ç”¨ flex æˆ– block å¸ƒå±€ */
    display: -webkit-box;

    /* å…³é”®ï¼šè®¾ç½®æ’åˆ—æ–¹å‘ä¸ºå‚ç›´ */
    -webkit-box-orient: vertical;

    /* å…³é”®ï¼šè®¾ç½®æ˜¾ç¤ºçš„è¡Œæ•° */
    -webkit-line-clamp: 2;

    /* æº¢å‡ºéšè— */
    overflow: hidden;

    /* ç¡®ä¿æ–‡å­—åœ¨å¿…è¦æ—¶æ¢è¡Œ */
    word-break: break-all;

    /* å•†ä¸šå·¥æ•´ï¼šè®¾ç½®åˆé€‚çš„å°æ ‡é¢˜è¡Œé«˜ï¼Œå¢åŠ é˜…è¯»æ„Ÿ */
    line-height: 1;
    min-height: 1em; /* å¯é€‰ï¼šå›ºå®šä¸¤è¡Œé«˜åº¦ï¼Œä¿æŒå¡ç‰‡æ•´é½ */
  }
}

.detail-content-container {
  padding: 10px 20px 20px 20px;
  height: calc(75vh);
  overflow: auto;

  .splits-wrapper{
    margin-bottom: 20px;
    .splits-label {
      margin-bottom: 10px;
      color: #99a0ae;
    }
  }
}


</style>
